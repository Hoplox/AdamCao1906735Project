{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Dataset Retrieval Pipeline.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Mount and module/library setup\n","\n","In this step, the shortcut setup in your Google Drive will be mounted to this Google Colab Notebook in order for access. It is important the steps were followed correctly in the user guide and file names are not changed.\n","\n","There will be a pop-up window in which Google Colab will request access to your Google Drive, this is normal and must be accepted to progress."],"metadata":{"id":"EHV3Ckz4StTh"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UEXW9x0Ur-5Y"},"outputs":[],"source":["#Import google collab drive usage, mount then enter directory for file access.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd /content/drive/MyDrive/adamcao-1906735-project/\n","\n","#Install required libraries\n","!pip install -q tensorflow-ranking\n","!pip install -U tensorflow_text\n","!pip install -q tf-models-official==2.4.0\n","!pip install -U nltk\n","\n","#Import all required modules and libraries\n","import pathlib\n","import tensorflow as tf\n","import tensorflow_ranking as tfr\n","import tensorflow_text as tf_text\n","from google.protobuf import text_format\n","import bz2\n","import json\n","import pandas as pd\n","import re\n","import random\n","from official.modeling import tf_utils\n","from official import nlp\n","from official.nlp import bert\n","import official.nlp.optimization\n","import official.nlp.bert.bert_models\n","import official.nlp.bert.configs\n","import official.nlp.bert.run_classifier\n","import official.nlp.bert.tokenization\n","import official.nlp.data.classifier_data_lib\n","import official.nlp.modeling.losses\n","import official.nlp.modeling.models\n","import official.nlp.modeling.networks\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n"]},{"cell_type":"markdown","source":["# Load NTCIR Collection\n","\n","Below the data provided by the NTCIR-15 research task is loaded into the notebook. (Sometimes there is a delay in the drive being mounted, restart runtime to resolve this)"],"metadata":{"id":"MWxmDoT3NrvG"}},{"cell_type":"code","source":["NTCIRCollectionPath = \"NTCIRCollection/\"\n","\n","trainTopics = pd.read_csv(NTCIRCollectionPath + \"data_search_e_train_topics.tsv\",sep='\\t', names=[\"QUERY ID\", \"QUERY STRING\"]).reset_index()\n","trainQrels = pd.read_csv(NTCIRCollectionPath + \"data_search_e_train_qrels.txt\", sep=' ', header=None, names=[\"QUERY ID\", \"DOC_ID\",\"REL_LEVEL\"]).reset_index()\n","testTopics = pd.read_csv(NTCIRCollectionPath + \"data_search_e_test_topics.tsv\",sep='\\t', names=[\"QUERY ID\", \"QUERY STRING\"]).reset_index()\n","testQrels = pd.read_csv(NTCIRCollectionPath + \"data_search_e_test_qrels.txt\", sep=' ', header=None, names=[\"QUERY ID\", \"DOC_ID\",\"REL_LEVEL\"]).reset_index()\n","collectionPath = NTCIRCollectionPath + \"data_search_e_collection.jsonl.bz2\"\n","\n","#Load collection data into a array of json.\n","collectionArr = []\n","\n","with bz2.BZ2File(collectionPath) as file:\n","  for line in file:\n","      line = line.decode().strip()\n","      if line in {\"[\", \"]\"}:\n","          continue\n","      if line.endswith(\",\"):\n","          line = line[:-1]\n","      collectionArr.append(json.loads(line))"],"metadata":{"id":"ck-UCFv1sL9a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Peek at the data\n","for x,y in collectionArr[0].items():\n","  print(x)\n","  print(y)\n","\n","print(trainTopics.head())\n","print(trainQrels.head())\n","print(testTopics.head())\n","print(testQrels.head())"],"metadata":{"id":"IcO1W0yusNaZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Splitting\n","\n","To prepare the data for model training, the training topics provided in the NTCIR-15 collection are split into a 90/10 ratio of training and valiation data. The validation data conists of 'high value' data for the models to be evaluated upon that contain all three of the different relevancy scores."],"metadata":{"id":"JtQ28VX-OMik"}},{"cell_type":"code","source":["#Split training topics into 90/10 Training/Validation set\n","queryDict = {}\n","for i1, r1 in trainTopics.iterrows():\n","  queryDict[r1['QUERY ID']] = {}\n","  queryDict[r1['QUERY ID']]['L0'] = 0\n","  queryDict[r1['QUERY ID']]['L1'] = 0\n","  queryDict[r1['QUERY ID']]['L2'] = 0\n","  for i2, r2 in trainQrels.iterrows():\n","    if r1['QUERY ID'] == r2['QUERY ID']:\n","        queryDict[r1['QUERY ID']][r2['REL_LEVEL']] += 1\n","  queryDict[r1['QUERY ID']]['total'] = queryDict[r1['QUERY ID']]['L0'] + queryDict[r1['QUERY ID']]['L1'] + queryDict[r1['QUERY ID']]['L2']\n","\n","goodQueries = []\n","for x in queryDict.items():\n","  if x[1]['L2'] > 1 and x[1]['L1'] > 1 and x[1]['L0'] > 1:\n","    goodQueries.append(x)\n","\n","valIDs = []\n","\n","#Random 10% of Training set\n","for x in range(10):\n","  ranPick = random.choice(goodQueries)[0]\n","  while ranPick in valIDs: \n","    ranPick = random.choice(goodQueries)[0]\n","  if ranPick not in valIDs:\n","    valIDs.append(ranPick)\n","\n","print(valIDs)\n","\n","trainTopicsSplitList = []\n","valTopicsSplitList = []\n","\n","for x in trainTopics.iterrows():\n","  if x[1]['QUERY ID'] in valIDs:\n","    valTopicsSplitList.append(x[1])\n","  else:\n","    trainTopicsSplitList.append(x[1])\n","\n","#Final Split loaded into Pandas DataFrames\n","valTopicsSplit = pd.DataFrame(valTopicsSplitList)\n","trainTopicsSplit = pd.DataFrame(trainTopicsSplitList)"],"metadata":{"id":"7y7jdPhZsP_y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Summarizer Function\n","\n","This function is used during the formatting process to shorten description text and only retain key information. This is so the BERT model can train on greater amounts of context information by truncating text that provides no context. Enabling more word tokens to be used within the max BERT sequence length."],"metadata":{"id":"sYpDAXHvOwZO"}},{"cell_type":"code","source":["# Input text - to summarize \n","def summarizer(text):\n","  # Tokenizing the text\n","  stopWords = set(stopwords.words(\"english\"))\n","  words = word_tokenize(text)\n","    \n","  # Creating a frequency table to keep the \n","  # score of each word\n","  freqTable = dict()\n","  for word in words:\n","      word = word.lower()\n","      if word in stopWords:\n","          continue\n","      if word in freqTable:\n","          freqTable[word] += 1\n","      else:\n","          freqTable[word] = 1\n","    \n","  # Creating a dictionary to keep the score\n","  # of each sentence\n","  sentences = sent_tokenize(text)\n","  sentenceValue = dict()\n","    \n","  for sentence in sentences:\n","      for word, freq in freqTable.items():\n","          if word in sentence.lower():\n","              if sentence in sentenceValue:\n","                  sentenceValue[sentence] += freq\n","              else:\n","                  sentenceValue[sentence] = freq\n","    \n","  sumValues = 0\n","  for sentence in sentenceValue:\n","      sumValues += sentenceValue[sentence]\n","    \n","  # Average value of a sentence from the original text\n","  average = int(sumValues / len(sentenceValue))\n","    \n","  # Storing sentences into our summary.\n","  summary = ''\n","  for sentence in sentences:\n","      if (sentence in sentenceValue) and (sentenceValue[sentence] > (1.2 * average)):\n","          summary += \" \" + sentence\n","\n","  summary = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", summary)\n","\n","  return summary"],"metadata":{"id":"smRrILAxsRK4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Title Feature Selection Formatting\n","\n","The titleFormat function is run to format the loaded data into JSON files in preparation to be converted into ELWC format as BERT inputs.\n","\n","This function converts the data only selecting the Title metadata for each dataset as the feature text for BERT to use. Data is also sorted into relevancy descending order for each ranking problem.\n","\n","It results in three JSON files being produced:\n","\n","* Training Set\n","* Validation Set\n","* Test Set\n","\n","These files will be saved to the FormattedData folder.\n","\n","A successful execution will print the following output:\n","\n","\n","\n","```\n","Topic ID: DS1-E-0096 | 86 / 86 Topic Ranking Problems\n","Completed writing to FormattedData/TitleTrain.json\n","TitleTrain.json data formatting complete.\n","\n","\n","Topic ID: DS1-E-0080 | 10 / 10 Topic Ranking Problems\n","Completed writing to FormattedData/TitleVal.json\n","TitleVal.json data formatting complete.\n","\n","\n","Topic ID: DS1-E-1096 | 96 / 96 Topic Ranking Problems\n","Completed writing to FormattedData/TitleTest.json\n","TitleTest.json data formatting complete.\n","```\n","\n","\n"],"metadata":{"id":"sG-BuoxpOrrU"}},{"cell_type":"code","source":["#Formatting into JSON using just Title in feature selection\n","def titleFormat(Topics, Qrels, folderOutput, filename):\n","  correctFormat = []\n","  NoDocIDs = len(Topics)\n","  counter = 1\n","  for i1, r1 in Topics.iterrows():\n","      print(\"\\rTopic ID: \" + r1['QUERY ID'] + \" | \" + str(counter) + \" / \" + str(NoDocIDs) + \" Topic Ranking Problems\", end=\"\")\n","      counter += 1\n","      documents0 = []\n","      documents1 = []\n","      documents2 = []\n","      for i2, r2 in Qrels.iterrows():\n","        if r1['QUERY ID'] == r2['QUERY ID']:\n","          if type(r2['REL_LEVEL']) == int:\n","            relevance = r2['REL_LEVEL']\n","          else:\n","            relevance = int(r2['REL_LEVEL'].replace('L', ''))\n","          if relevance == 2:\n","            for data in collectionArr:\n","              if r2['DOC_ID'] == data['id']:\n","                docText = data['title']\n","                documents2.append({ \"relevance\" : relevance, \"docText\": docText })\n","                \n","          elif relevance == 1:\n","            for data in collectionArr:\n","              if r2['DOC_ID'] == data['id']:\n","                docText = data['title']\n","                documents1.append({ \"relevance\" : relevance, \"docText\": docText })\n","\n","          elif relevance == 0:\n","            for data in collectionArr:\n","              if r2['DOC_ID'] == data['id']:\n","                docText = data['title']\n","                documents0.append({ \"relevance\" : relevance, \"docText\": docText })\n","\n","      documents = documents2 + documents1 + documents0\n","      if len(documents) != 0:\n","        correctFormat.append({ \"queryText\" : r1['QUERY STRING'], \"documents\" : documents})\n","\n","  #Export\n","  JsonDict = {}\n","  JsonDict['rankingProblems'] = correctFormat\n","  JSON = json.dumps(JsonDict,indent=1)\n","  Output = folderOutput + filename\n","\n","  with open(Output, 'w', encoding='utf-8') as f:\n","      json.dump(JsonDict, f, ensure_ascii=False, indent=1)\n","\n","  print(\"\")\n","  print(\"Completed writing to \" + Output)\n","  print(filename + \" data formatting complete.\")\n","  print(\"\\n\")\n","\n","titleFormat(trainTopicsSplit , trainQrels, \"FormattedData/\", \"TitleTrain.json\")\n","titleFormat(valTopicsSplit , trainQrels, \"FormattedData/\", \"TitleVal.json\")\n","titleFormat(testTopics , testQrels, \"FormattedData/\", \"TitleTest.json\")"],"metadata":{"id":"1QCeqb5CsTaW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Title + Desc Feature Selection Formatting\n","\n","The titleDescFormat function is run to format the loaded data into JSON files in preparation to be converted into ELWC format as BERT inputs.\n","\n","This function converts the data selecting the Title and Description metadata for each dataset as the feature text for BERT to use. Data is also sorted into relevancy descending order for each ranking problem.\n","\n","It results in three JSON files being produced:\n","\n","* Training Set\n","* Validation Set\n","* Test Set\n","\n","These files will be saved to the FormattedData folder.\n","\n","A successful execution will print the following output:\n","\n","\n","\n","```\n","Topic ID: DS1-E-0096 | 86 / 86 Topic Ranking Problems\n","Completed writing to FormattedData/TitleDescTrain.json\n","TitleDescTrain.json data formatting complete.\n","\n","\n","Topic ID: DS1-E-0080 | 10 / 10 Topic Ranking Problems\n","Completed writing to FormattedData/TitleDescVal.json\n","TitleDescVal.json data formatting complete.\n","\n","\n","Topic ID: DS1-E-1096 | 96 / 96 Topic Ranking Problems\n","Completed writing to FormattedData/TitleDescTest.json\n","TitleDescTest.json data formatting complete.\n","```\n","\n","\n"],"metadata":{"id":"ZPw5b0rJQrf0"}},{"cell_type":"code","source":["#Formatting into JSON using Title and Description in feature selection\n","def titleDescFormat(Topics, Qrels, folderOutput, filename):\n","  correctFormat = []\n","  NoDocIDs = len(Topics)\n","  counter = 1\n","  for i1, r1 in Topics.iterrows():\n","      print(\"\\rTopic ID: \" + r1['QUERY ID'] + \" | \" + str(counter) + \" / \" + str(NoDocIDs) + \" Topic Ranking Problems\", end=\"\")\n","      counter += 1\n","      documents0 = []\n","      documents1 = []\n","      documents2 = []\n","      for i2, r2 in Qrels.iterrows():\n","        if r1['QUERY ID'] == r2['QUERY ID']:\n","          \n","          if type(r2['REL_LEVEL']) == int:\n","            relevance = r2['REL_LEVEL']\n","          else:\n","            relevance = int(r2['REL_LEVEL'].replace('L', ''))\n","          if relevance == 2:\n","            for data in collectionArr:\n","              if r2['DOC_ID'] == data['id']:\n","\n","                docText = \"\"\n","                if len(data['description']) == 0:\n","                  docText = data['title']\n","                else:\n","                  descText = summarizer(data['description']).replace('\\n','')\n","                  if len(descText) < 1:\n","                    docText = data['title'] + \" || \" + data['description'].replace('\\n','')\n","                  else:\n","                    docText = data['title'] + \" || \" + descText\n","                \n","                documents2.append({ \"relevance\" : relevance, \"docText\": docText })\n","          elif relevance == 1:\n","            for data in collectionArr:\n","              if r2['DOC_ID'] == data['id']:\n","\n","                docText = \"\"\n","                if len(data['description']) == 0:\n","                  docText = data['title']\n","                else:\n","                  descText = summarizer(data['description']).replace('\\n','')\n","                  if len(descText) < 1:\n","                    docText = data['title'] + \" || \" + data['description'].replace('\\n','')\n","                  else:\n","                    docText = data['title'] + \" || \" + descText\n","                \n","                documents1.append({ \"relevance\" : relevance, \"docText\": docText })\n","\n","          elif relevance == 0:\n","            for data in collectionArr:\n","              if r2['DOC_ID'] == data['id']:\n","\n","                docText = \"\"\n","                if len(data['description']) == 0:\n","                  docText = data['title']\n","                else:\n","                  descText = summarizer(data['description']).replace('\\n','')\n","                  if len(descText) < 1:\n","                    docText = data['title'] + \" || \" + data['description'].replace('\\n','')\n","                  else:\n","                    docText = data['title'] + \" || \" + descText\n","                \n","                documents0.append({ \"relevance\" : relevance, \"docText\": docText })\n","\n","      documents = documents2 + documents1 + documents0\n","      if len(documents) != 0:\n","        correctFormat.append({ \"queryText\" : r1['QUERY STRING'], \"documents\" : documents})\n","\n","  #Export\n","  JsonDict = {}\n","  JsonDict['rankingProblems'] = correctFormat\n","  JSON = json.dumps(JsonDict,indent=1)\n","  Output = folderOutput + filename\n","\n","  with open(Output, 'w', encoding='utf-8') as f:\n","      json.dump(JsonDict, f, ensure_ascii=False, indent=1)\n","\n","  print(\"\")\n","  print(\"Completed writing to \" + Output)\n","  print(filename + \" data formatting complete.\")\n","  print(\"\\n\")\n","\n","titleDescFormat(trainTopicsSplit , trainQrels, \"FormattedData/\", \"TitleDescTrain.json\")\n","titleDescFormat(valTopicsSplit , trainQrels, \"FormattedData/\", \"TitleDescVal.json\")\n","titleDescFormat(testTopics , testQrels, \"FormattedData/\", \"TitleDescTest.json\")"],"metadata":{"id":"FS2DPdwrsS-y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Title + Tags Feature Selection Formatting\n","\n","The titleTagsFormat function is run to format the loaded data into JSON files in preparation to be converted into ELWC format as BERT inputs.\n","\n","This function converts the data selecting the Title and Tags metadata for each dataset as the feature text for BERT to use. Data is also sorted into relevancy descending order for each ranking problem.\n","\n","It results in three JSON files being produced:\n","\n","* Training Set\n","* Validation Set\n","* Test Set\n","\n","These files will be saved to the FormattedData folder.\n","\n","A successful execution will print the following output:\n","\n","\n","\n","```\n","Topic ID: DS1-E-0096 | 86 / 86 Topic Ranking Problems\n","Completed writing to FormattedData/TitleTagsTrain.json\n","TitleTagsTrain.json data formatting complete.\n","\n","\n","Topic ID: DS1-E-0080 | 10 / 10 Topic Ranking Problems\n","Completed writing to FormattedData/TitleTagsVal.json\n","TitleTagsVal.json data formatting complete.\n","\n","\n","Topic ID: DS1-E-1096 | 96 / 96 Topic Ranking Problems\n","Completed writing to FormattedData/TitleTagsTest.json\n","TitleTagsTest.json data formatting complete.\n","```\n","\n","\n"],"metadata":{"id":"gL8zbniIQ4q4"}},{"cell_type":"code","source":["#Formatting into JSON using Title and Tags in feature selection\n","def titleTagsFormat(Topics, Qrels, folderOutput, filename):\n","  correctFormat = []\n","  NoDocIDs = len(Topics)\n","  counter = 1\n","  for i1, r1 in Topics.iterrows():\n","      print(\"\\rTopic ID: \" + r1['QUERY ID'] + \" | \" + str(counter) + \" / \" + str(NoDocIDs) + \" Topic Ranking Problems\", end=\"\")\n","      counter += 1\n","      documents0 = []\n","      documents1 = []\n","      documents2 = []\n","      for i2, r2 in Qrels.iterrows():\n","        if r1['QUERY ID'] == r2['QUERY ID']:\n","\n","          if type(r2['REL_LEVEL']) == int:\n","            relevance = r2['REL_LEVEL']\n","          else:\n","            relevance = int(r2['REL_LEVEL'].replace('L', ''))\n","          if relevance == 2:\n","            for data in collectionArr:\n","              if r2['DOC_ID'] == data['id']:\n","                tags = \"\"\n","                for x in data['data_fields']['tags']:\n","                  tags = tags + x + \" \"\n","                docText = data['title'] + \", \" + tags\n","                documents2.append({ \"relevance\" : relevance, \"docText\": docText })\n","                \n","          elif relevance == 1:\n","            for data in collectionArr:\n","              if r2['DOC_ID'] == data['id']:\n","                tags = \"\"\n","                for x in data['data_fields']['tags']:\n","                  tags = tags + x + \" \"\n","                docText = data['title'] + \", \" + tags\n","                documents1.append({ \"relevance\" : relevance, \"docText\": docText })\n","\n","          elif relevance == 0:\n","            for data in collectionArr:\n","              if r2['DOC_ID'] == data['id']:\n","                tags = \"\"\n","                for x in data['data_fields']['tags']:\n","                  tags = tags + x + \" \"\n","                docText = data['title'] + \", \" + tags\n","                documents0.append({ \"relevance\" : relevance, \"docText\": docText })\n","\n","      documents = documents2 + documents1 + documents0\n","      if len(documents) != 0:\n","        correctFormat.append({ \"queryText\" : r1['QUERY STRING'], \"documents\" : documents})\n","\n","  #Export\n","  JsonDict = {}\n","  JsonDict['rankingProblems'] = correctFormat\n","  JSON = json.dumps(JsonDict,indent=1)\n","  Output = folderOutput + filename\n","\n","  with open(Output, 'w', encoding='utf-8') as f:\n","      json.dump(JsonDict, f, ensure_ascii=False, indent=1)\n","\n","  print(\"\")\n","  print(\"Completed writing to \" + Output)\n","  print(filename + \" data formatting complete.\")\n","  print(\"\\n\")\n","\n","titleTagsFormat(trainTopicsSplit , trainQrels, \"FormattedData/\", \"TitleTagsTrain.json\")\n","titleTagsFormat(valTopicsSplit , trainQrels, \"FormattedData/\", \"TitleTagsVal.json\")\n","titleTagsFormat(testTopics , testQrels, \"FormattedData/\", \"TitleTagsTest.json\")"],"metadata":{"id":"1HdarIIRGTkB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# View Max List Size\n","\n","This function can be run to view the maximum list size of a ranking problem in the exported JSON files, this information is useful for setting the list size model training parameter."],"metadata":{"id":"QP9eXYOPRFDX"}},{"cell_type":"code","source":["def listSize(jsondir):\n","  f = open(jsondir)\n","  Data = json.load(f)\n","  f.close()\n","  docLens = []\n","  for x in Data['rankingProblems']:\n","    docLens.append( len(x['documents'])) \n","  return max(docLens)\n","\n","print(listSize('FormattedData/TitleTagsTrain.json'))\n","print(listSize('FormattedData/TitleTagsVal.json'))\n","print(listSize('FormattedData/TitleTagsTest.json'))"],"metadata":{"id":"tdJikT8usWLb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# JSON to ELWC Conversion\n","\n","This takes the three exported JSON files and converts them from JSON into ELWC format as .tfrecords.\n","\n","The sequence length must be set here, it will correspond to the BERT training sequence length when using it as data.\n","\n","Example Output:\n","\n","```\n","Utility to convert between JSON and ELWC for TFR-Bert\n","\n","Model Parameters: \n","Vocabulary filename: cased_L-12_H-768_A-12/vocab.txt\n","sequence_length: 256\n","do_lower_case: False\n","Input file:  FormattedData/TitleTagsTrain.json\n","Output file: FormattedData/TitleTagsData/256TrainELWC.tfrecord\n","\n","Success. \n","\n","Utility to convert between JSON and ELWC for TFR-Bert\n","\n","Model Parameters: \n","Vocabulary filename: cased_L-12_H-768_A-12/vocab.txt\n","sequence_length: 256\n","do_lower_case: False\n","Input file:  FormattedData/TitleTagsVal.json\n","Output file: FormattedData/TitleTagsData/256ValELWC.tfrecord\n","\n","Success. \n","\n","Utility to convert between JSON and ELWC for TFR-Bert\n","\n","Model Parameters: \n","Vocabulary filename: cased_L-12_H-768_A-12/vocab.txt\n","sequence_length: 256\n","do_lower_case: False\n","Input file:  FormattedData/TitleTagsTest.json\n","Output file: FormattedData/TitleTagsData/256TestELWC.tfrecord\n","\n","Success. \n","```\n","\n"],"metadata":{"id":"CRF4_UuYRehD"}},{"cell_type":"code","source":["#For Title only feature selection\n","!BERT_DIR=\"cased_L-12_H-768_A-12\"  && \\\n","python bertPython/tfrbert_convert_json_to_elwc.py \\\n","    --vocab_file=${BERT_DIR}/vocab.txt \\\n","    --sequence_length=256 \\\n","    --input_file=FormattedData/TitleTrain.json \\\n","    --output_file=FormattedData/TitleData/256TrainELWC.tfrecord\n","\n","!BERT_DIR=\"cased_L-12_H-768_A-12\"  && \\\n","python bertPython/tfrbert_convert_json_to_elwc.py \\\n","    --vocab_file=${BERT_DIR}/vocab.txt \\\n","    --sequence_length=256 \\\n","    --input_file=FormattedData/TitleVal.json \\\n","    --output_file=FormattedData/TitleData/256ValELWC.tfrecord\n","\n","!BERT_DIR=\"cased_L-12_H-768_A-12\"  && \\\n","python bertPython/tfrbert_convert_json_to_elwc.py \\\n","    --vocab_file=${BERT_DIR}/vocab.txt \\\n","    --sequence_length=256 \\\n","    --input_file=FormattedData/TitleTest.json \\\n","    --output_file=FormattedData/TitleData/256TestELWC.tfrecord"],"metadata":{"id":"dsER9mI6sXNv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#For Title + Desc only feature selection\n","!BERT_DIR=\"cased_L-12_H-768_A-12\"  && \\\n","python bertPython/tfrbert_convert_json_to_elwc.py \\\n","    --vocab_file=${BERT_DIR}/vocab.txt \\\n","    --sequence_length=256 \\\n","    --input_file=FormattedData/TitleDescTrain.json \\\n","    --output_file=FormattedData/TitleDescData/256TrainELWC.tfrecord\n","\n","!BERT_DIR=\"cased_L-12_H-768_A-12\"  && \\\n","python bertPython/tfrbert_convert_json_to_elwc.py \\\n","    --vocab_file=${BERT_DIR}/vocab.txt \\\n","    --sequence_length=256 \\\n","    --input_file=FormattedData/TitleDescVal.json \\\n","    --output_file=FormattedData/TitleDescData/256ValELWC.tfrecord\n","\n","!BERT_DIR=\"cased_L-12_H-768_A-12\"  && \\\n","python bertPython/tfrbert_convert_json_to_elwc.py \\\n","    --vocab_file=${BERT_DIR}/vocab.txt \\\n","    --sequence_length=256 \\\n","    --input_file=FormattedData/TitleDescTest.json \\\n","    --output_file=FormattedData/TitleDescData/256TestELWC.tfrecord"],"metadata":{"id":"S7JZQGqSSMOq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#For Title + Tags feature selection\n","!BERT_DIR=\"cased_L-12_H-768_A-12\"  && \\\n","python bertPython/tfrbert_convert_json_to_elwc.py \\\n","    --vocab_file=${BERT_DIR}/vocab.txt \\\n","    --sequence_length=256 \\\n","    --input_file=FormattedData/TitleTagsTrain.json \\\n","    --output_file=FormattedData/TitleTagsData/256TrainELWC.tfrecord\n","\n","!BERT_DIR=\"cased_L-12_H-768_A-12\"  && \\\n","python bertPython/tfrbert_convert_json_to_elwc.py \\\n","    --vocab_file=${BERT_DIR}/vocab.txt \\\n","    --sequence_length=256 \\\n","    --input_file=FormattedData/TitleTagsVal.json \\\n","    --output_file=FormattedData/TitleTagsData/256ValELWC.tfrecord\n","\n","!BERT_DIR=\"cased_L-12_H-768_A-12\"  && \\\n","python bertPython/tfrbert_convert_json_to_elwc.py \\\n","    --vocab_file=${BERT_DIR}/vocab.txt \\\n","    --sequence_length=256 \\\n","    --input_file=FormattedData/TitleTagsTest.json \\\n","    --output_file=FormattedData/TitleTagsData/256TestELWC.tfrecord"],"metadata":{"id":"_5n_GdTpSNTg"},"execution_count":null,"outputs":[]}]}